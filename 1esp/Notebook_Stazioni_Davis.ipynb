{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0a610f3",
   "metadata": {},
   "source": [
    "<span style=\"font-size: x-large;\">**IMPOSTAZIONE AMBIENTE DI LAVORO**<span style=\"font-size: x-large;\">  \n",
    " \n",
    "<span style=\"font-size: large;\">**1. Creazione cartelle**  \n",
    " \n",
    "Come primo passo, organizziamo lo spazio di lavoro dove salvare dati, risultati e figure dell'esperienza di laboratorio. Creiamo quindi le seguenti cartelle di lavoro sul computer:  \n",
    "- *DATI_ORIGINALI*  \n",
    "    cartella dove salvare i dati delle stazioni Davis originali. I dati possono essere scaricati dal virtuale del corso di \"Laboratorio di Fisica dell'Atmosfera\" al seguente link:\n",
    "https://virtuale.unibo.it/course/view.php?id=51454#section-3 \n",
    "- *DATI_PROCESSATI*  \n",
    "    cartella dove salvare i dati processati delle stazioni Davis e i risultati delle analisi che verranno effettute durante le esperienze di laboratorio.  \n",
    "- *FIGURE*  \n",
    "    cartella dove salvare le figure da inserire successivamente nell'elaborato finale descrivente le esperienze di laboratorio.  \n",
    "  \n",
    "I nomi delle cartelle possono ovviamente essere scelti a piacimento.\n",
    "Si consiglia però di organizzare in cartelle separate i dati originali e i dati processati, al fine di evitare di confodere gli uni con gli altri al momento delle analisi.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fd7986",
   "metadata": {},
   "source": [
    "<span style=\"font-size: large;\">**2. Inizializzazione ambiente di calcolo**  \n",
    "\n",
    "Una volta creato lo spazio di lavoro sul proprio computer, inizializziamo l’ambiente di calcolo di Python caricando i pacchetti necessari alla gestione dei dati, alla loro analisi e alla rappresentazione grafica dei risultati ottenuti.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27da7f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pacchetto per apertura dati salvati in cartelle zippate\n",
    "import zipfile\n",
    "\n",
    "# Pacchetti per analisi dati\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import seaborn as sns\n",
    "import warnings; warnings.simplefilter(\"ignore\")\n",
    "from functools import reduce\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import math\n",
    "import pytz\n",
    "\n",
    "# Pacchetti per visualizzazioni grafiche\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import calendar\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778a73f6",
   "metadata": {},
   "source": [
    "<span style=\"font-size: x-large;\">**GESTIONE DATI**</span>  \n",
    "  \n",
    "  **<span style=\"font-size: large;\">1. Estrazione dati da cartella ZIP**\n",
    "\n",
    "I dati delle 3 stazioni Davis sono salvati all'interno di un file ZIP. Attraverso il pacchetto Python *\"zipfile\"* è possibile estrarre i file della cartella compressa direttamente da Python e salvarli nel percorso scelto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5529ac2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "percorso = \"./DATI_ORIGINALI/\"\n",
    "\n",
    "# Il percorso va cambiato in funzione di dove sono i vostri dati\n",
    "nome_file = \"Dati_Stazione.zip\"\n",
    "file= str(percorso)+str(nome_file)\n",
    "\n",
    "with zipfile.ZipFile(file, 'r') as zip_ref:\n",
    "    zip_ref.extractall(percorso)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8f8ff9",
   "metadata": {},
   "source": [
    "  **<span style=\"font-size: large;\">2. Lettura dati**  \n",
    "    \n",
    "I modi per aprire e leggere file in Python sono molteplici e la scelta migliore dipende dal formato dei dati e dalla loro struttura. Pacchetti particolarmente usati a questo scopo sono *\"xarray\"* (specialmente per dati climatici in formato netcdf \".nc\"), *\"numpy\"* e *\"pandas\"*.  \n",
    "\n",
    "I dati delle stazioni Davis sono salvati in tre differenti file \".txt\", ciascuno associato ad una singola stazione Davis. Questi file sono costruiti in formato tabellare, in modo da avere nelle prime tre colonne la data, l'orario e l'intervallo temporale, mentre nelle successive colonne vengono riportate le misurazioni di diverse variabili fisiche. \n",
    "    \n",
    "Per capire meglio come sono fatti, apriamo uno dei file \".txt\".\n",
    "\n",
    "Una scelta idonea, ma non unica, per aprire file in formato tabellare è adoperare il pacchetto *\"pandas\"*.  \n",
    "\n",
    "Al fine di evitare di ripetere l'operazione di apertura dei file per ciascuna singola stazione, si è impostato un ciclo *\"for\"* reiterando l'operazione di lettura dei dati un numero di volte pari al numero delle stazioni stesse. Seppur questo non sia necessario ai fini della funzionalità dello script, ne aiuta molto la leggibilità.\n",
    "    \n",
    "Onde evitare problemi con la successiva gestione dei dataframes, si procede con l'aprire i dati delle stazioni con un approccio quanto più generale possibile, vale a dire:\n",
    "\n",
    "- leggere i dati riga per riga (eliminando tutti gli spazi bianchi tra le colonne),\n",
    "- salvare le righe in un oggetto \"lista\" e poi trasformarlo in un dataframe\n",
    "- tenere solo le righe del dataframe della stazione C dove tutte le colonne contengono solo caratteri alfabetici (a-zA-Z), caratteri numerici (0-9) o il segno meno (-).    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09cb161",
   "metadata": {},
   "outputs": [],
   "source": [
    "stazioni = [\"A\",\"B\",\"C\"]\n",
    "\n",
    "for stazione in stazioni:\n",
    "    \n",
    "    print(\"Stazione \"+stazione)\n",
    "\n",
    "    file = percorso+\"Dati Meteo - Stazione \"+stazione+\".txt\"\n",
    "    \n",
    "    # Di seguito si inizializza una lista vuota, all'interno della quale si va a caricare ogni linea della tabella \".txt\".\n",
    "    # In questo contesto, è importante notare che ogni colonna dei file è separata da spazi bianchi, che devono essere tenuti \n",
    "    # in considerazione al momento del caricamento dei dati.\n",
    "    # Per farlo, si adopera \"line.split()\", che legge riga per riga la tabella \".txt\" (compreso il nome delle colonne) ed \n",
    "    # elimina tutti gli spazi tra una colonna e l'altra.\n",
    "\n",
    "    lista = []\n",
    "    with open(file, encoding='ISO-8859-1') as f:\n",
    "        for line in f:\n",
    "            l = line.split()\n",
    "            lista.append(l)\n",
    "    \n",
    "    # A questo punto, trasformiamo la lista in un DataFrame di pandas, con le colonne nominate come nel file originale.\n",
    "    df = pd.DataFrame(lista[1:],columns=lista[0])\n",
    "    \n",
    "    # Seppur non necessario ai fini delle analisi, con i prossimi due comandi si sistemano le intestazioni delle colonne:\n",
    "    # 1. Eliminiamo la virgola alla fine dei nomi delle diverse colonne nel file originale (es. \"wndSpeed,\")\n",
    "    df.columns = df.columns.str.rstrip(',')    \n",
    "    # 2. Eliminiamo il carattere \"#\" di fronte alla parola \"Date\" della prima colonna (\"#Date\")\n",
    "    nome_prima_colonna = df.columns[0][1:]\n",
    "    df.rename(columns={df.columns[0]: nome_prima_colonna}, inplace=True)\n",
    "    \n",
    "    # I dati della stazione C presentano dei caratteri verso la fine dell'intervallo temporale che non sono facilmente decifrati/interpretati da python.\n",
    "    # Si procede quindi a selezionare solo quelle righe del dataframe della stazione C dove tutte le colonne contengono solo \n",
    "    # caratteri alfabetici (a-zA-Z), caratteri numerici (0-9) e il segno meno (-).\n",
    "    \n",
    "    if stazione == \"C\":\n",
    "        for col in range(df.shape[1]):\n",
    "            column = df.columns[col]\n",
    "            mask = df[str(column)].str.contains(r'^[a-zA-Z0-9.-]+$', na=False)\n",
    "            df = df[mask]\n",
    "    else:\n",
    "        pass\n",
    "        \n",
    "    globals()['df_'+stazione] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3824a649",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daafadf9",
   "metadata": {},
   "source": [
    "<span style=\"font-size: large;\">**3. La variabile *Tempo***  \n",
    "  \n",
    "Le prime tre colonne dei file rappresentano la data, l'orario e l'intervallo temporale delle misurazioni.\n",
    "\n",
    "Quando si lavora con dati meteo-climatici, la dimensione \"tempo\" è fondamentale in quanto la maggior parte delle operazioni di gestione dei dati viene spesso svolta proprio lungo questa dimensione. Per questo motivo, molti pacchetti (non solo in Python) sono costruiti proprio per agevolare specifiche operazioni lungo la dimensione temporale, quali ad esempio medie mensili, calcolo della climatologia, selezione dei dati di una sola stagione, etc.\n",
    "\n",
    "Dato che anche durante questa esperienza di laboratorio dovremo effettuare diverse operazioni lungo la dimensione temporale, conviene creare una nuova variabile di supporto (*\"Datetime\"*) contente le date in formato Anno-mese-giorno ora:minuto.\n",
    "\n",
    "Nello script di seguito, le colonne originali *\"Date\"* e *\"Time\"* vengono eliminate a seguito della creazione della colonna *\"Datetime\"* con il fine ultimo di avere dataframes non ridondanti e più facili da intepretare e leggere. Queste colonne possono però essere mantenute all'interno dei dataframes senza alcun problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727e6bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stazioni = [\"A\",\"B\",\"C\"]\n",
    "\n",
    "for stazione in stazioni:\n",
    "    \n",
    "    print(\"Stazione \"+stazione)\n",
    "    \n",
    "    df = globals()[\"df_\"+stazione]\n",
    "        \n",
    "    day = df['Date'].values; hour = df['Time'].values\n",
    "    date_final = np.array([datetime.strptime(data + ' ' + ora, \"%Y%m%d %H.%M\") for data, ora in zip(day, hour)])\n",
    "    df.insert(2,'Datetime',date_final)\n",
    "    df.drop(df.columns[:2],axis=1, inplace=True)\n",
    "            \n",
    "    df.iloc[:, 1:] = df.iloc[:, 1:].apply(pd.to_numeric, errors='coerce')\n",
    "                    \n",
    "    globals()[\"df_\"+stazione] = df #non serve se non uso copy in df = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be6843c",
   "metadata": {},
   "source": [
    "Dando una occhiata più attenta ai dati della stazione A, ci si rende conto che la variabile *\"Datetime\"* non è ordinata. Difatti le ore non sono disposte in modo regolare. Si procede quindi a riordinare tutti i dataframes lungo la dimensione temporale con *\"sort_values(by='Datetime')\"*.  \n",
    "\n",
    "Inoltre, guardando la dimensione *\"Interval\"* si vede che le misure sono state prese a diversi intervalli temporali, cosa di cui si dovrà tener conto al momento dell'analisi dei dati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a97460f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stazioni = [\"A\",\"B\",\"C\"]\n",
    "\n",
    "for stazione in stazioni:\n",
    "    \n",
    "    globals()[\"df_\"+stazione] = globals()[\"df_\"+stazione].sort_values(by='Datetime', ignore_index=True) #riordina indici di riga"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c13d0e5",
   "metadata": {},
   "source": [
    "<span style=\"font-size: large;\">**4. Qualche operazione di base**\n",
    "    \n",
    "Ora che abbiamo aperto i dati e abbiamo sistemato la dimensione tempo, cominciamo ad imparare a manipolare i dati delle stazioni meteo con qualche operazione di base."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39216274",
   "metadata": {},
   "source": [
    "# Esempio 1 --> Estrazione dei valori di una specifica colonna\n",
    "\n",
    "inTemp = df_A['inTemp'].copy()\n",
    "print(inTemp)\n",
    "\n",
    "# Esempio 2 --> Qualche operazione aritmetica\n",
    "\n",
    "inTemp_mean = inTemp.mean(skipna=True)\n",
    "inTemp_std = inTemp.std(skipna=True)\n",
    "inTemp_max = inTemp.max(skipna=True)\n",
    "inTemp_min = inTemp.min(skipna=True)\n",
    "\n",
    "print(\"\\nLa inTemp media della stazione A è \" + str(round(inTemp_mean,2)) +'°C, con una variabilità di ' + str(round(inTemp_std))+'°C.')\n",
    "print(\"\\nLa inTemp massima ha raggiunto \"+ str(round(inTemp_max,2)) +'°C, mentre la inTemp minima ha raggiunto '+ str(round(inTemp_min,2)) +'°C.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c64f806",
   "metadata": {},
   "source": [
    "# Esempio 3 --> Interroghiamo la dimensione tempo\n",
    "\n",
    "# L'utilità di aver creato una variabile \"Datetime\", specificando il formato delle date, è che ci permette di interrogare\n",
    "# la variabile stessa in modo molto semplice, e di estrarre informazioni quali anno, mese, giorno, etc. con una sola riga di codice. \n",
    "# Queste informazioni potranno poi essere usate per operazioni di filtraggio dei dataframes.\n",
    "\n",
    "# Stampiamo, giusto come esempio, la prima e ultima data della nostra timeseries, seguita dal suo anno, mese e giorno.\n",
    "\n",
    "# NOTA: In Python, la numerazione inizia con lo zero (0), e non con l'uno (1) come in altri linguaggi di programmazione.\n",
    "# Questo vuol dire che il primo elemento di qualsiasi tipologia di oggetto (lista, array n-dimensionale, dizionario) viene\n",
    "# richimato adoperando lo zero. \n",
    "# Per questo motivo, la prima data del dataframe associato alla stazione A viene di seguito richiamata con \"Datetime.iloc[0]\"\n",
    "\n",
    "print(df_A.Datetime)\n",
    "\n",
    "print(\"\\n\") # Stampare \"\\n\" serve solo a creare uno spazio tra la stampa di quanto sopra e la stampa di quanto di seguito.\n",
    "\n",
    "print(f\"La prima data è:\\n{df_A.Datetime.iloc[0]}\\n\")\n",
    "print(f\"vale a dire il giorno {df_A.Datetime.iloc[0].day} del mese {df_A.Datetime.iloc[0].month} dell'anno {df_A.Datetime.iloc[0].year}\\n\")\n",
    "\n",
    "print(f\"L'ultima data è:\\n{df_A.Datetime.iloc[-1]}\\n\")\n",
    "print(f\"vale a dire il giorno {df_A.Datetime.iloc[-1].day} del mese {df_A.Datetime.iloc[-1].month} dell'anno {df_A.Datetime.iloc[-1].year}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277b6082",
   "metadata": {},
   "source": [
    "# Esempio 4 --> Filtriamo i dati seleziando solo quelli di nostro interesse.\n",
    "\n",
    "# Esempio 4.1: Filtraggio di uno specifico intervallo temporale\n",
    "# Il simbolo \"|\" sta ad indicare la funzione logica \"or\"\n",
    "df_A_DJF = df_A[(df_A[\"Datetime\"].dt.month == 12)|(df_A[\"Datetime\"].dt.month == 1)|(df_A[\"Datetime\"].dt.month == 2)]\n",
    "df_A_DJF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6151ee8e",
   "metadata": {},
   "source": [
    "# Esempio 4.2: Filtraggio di un intervallo di valori\n",
    "# Il simbolo \"&\" sta a indicare la funzione logica \"and\"\n",
    "df_A_filtered = df_A[(df_A['wndSpeed'] >= 0)&(df_A['wndSpeed']<=25)&(df_A['wndDir'] >= 0)&(df_A['wndDir']<360)]\n",
    "df_A_filtered['wndSpeed'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e52a4b5",
   "metadata": {},
   "source": [
    "<span style=\"font-size: x-large;\">**GRAFICI**</span>  \n",
    "\n",
    "In questa sezione, si forniscono alcuni esempi di grafici che potrebbero risultare utili ai fini dell'analisi dei dati delle stazioni Davis.  \n",
    "\n",
    "<u>NOTA IMPORTANTE</u>: I grafici devono SEMPRE essere corredati di tutte le informazioni necessarie a comprenderli, anche quando possono sembrare banali e ridondanti: titolo degli assi, unità di misura di tutte le variabili richiamate, legenda, barra dei colori, limite degli assi ben definiti, etc. \n",
    "  \n",
    "  <span style=\"font-size: large;\">**1. Istogrammi**  \n",
    "  \n",
    "  Gli istogrammi sono una rappresentazione grafica della distribuzione di un insieme di dati, che mostra la frequenza con cui ciascun valore o intervallo di valori si verifica in un insieme di dati. Gli istogrammi sono comunemente utilizzati per esaminare la forma della distribuzione di dati numerici e per identificare tendenze, modi, e altre caratteristiche.\n",
    "\n",
    "Ai fini di una rappresentazione grafica intuitiva, solitamente l'asse x degli istrogrammi rappresenta il range dei dati diviso in intervalli o \"bin\". L'asse y invece rappresenta la frequenza con cui i dati ricadono in ciascun bin. Quindi, l'altezza di ciascun bin rappresenta il numero di osservazioni che rientrano in uno specifico intervallo.  \n",
    "\n",
    "I metodi per produrre istogrammi su python sono diversi. Un approccio molto usato è adoperare la libreria *\"seaborn\"*, vale a dire una libreria di visualizzazione dati per analisi statistiche. Un altro approccio, consigliabile in casi semplici, è disegnare direttamente delle barre rettangolari in un piano cartesiano, con specifiche posizioni lungo l'asse x e dimensioni lungo l'asse y.  \n",
    "\n",
    "Di seguito si riportano due esempi, cogliendo l'occasione per analizzare i dati delle stazioni Davis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e66686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ESEMPIO 1. Come si distribuiscono le diverse risoluzioni temporali?\n",
    "\n",
    "plt.figure(figsize=(8, 10))\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "bins = np.arange(-0.5,int(df_A['Interval'].max())+1)\n",
    "hist = sns.histplot(df_A['Interval'], bins=bins,kde=False, color='blue')\n",
    "plt.yscale('log')\n",
    "plt.title('Stazione A',fontweight='bold')\n",
    "plt.ylabel(\"Numero di misure\"); plt.xlabel(\"Intervallo (minuti)\")\n",
    "plt.ylim(10**(0),10**(6))\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "bins = np.arange(-0.5,int(df_B['Interval'].max())+1)\n",
    "hist = sns.histplot(df_B['Interval'], bins=bins,kde=False, color='green')\n",
    "plt.yscale('log')\n",
    "plt.title('Stazione B',fontweight='bold')\n",
    "plt.ylabel(\"Numero di misure\"); plt.xlabel(\"Intervallo (minuti)\")\n",
    "plt.ylim(10**(0),10**(6))\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "bins = np.arange(-0.5,int(df_C['Interval'].max())+1)\n",
    "hist = sns.histplot(df_C['Interval'], bins=bins,kde=False, color='orange')\n",
    "plt.yscale('log')\n",
    "plt.title('Stazione C',fontweight='bold')\n",
    "plt.ylabel(\"Numero di misure\"); plt.xlabel(\"Intervallo (minuti)\")\n",
    "plt.ylim(10**(0),10**(6))\n",
    "\n",
    "plt.suptitle('Intervalli Temporali',fontweight='bold',x=0.53)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e39e2a4",
   "metadata": {},
   "source": [
    "Come si può vedere, la stazione A presenta dei dati presi a intervalli temporali pari a [1, 5, 10] minuti, mentre la stazione B a [1, 10] minuti.  \n",
    "Se vogliamo solo misure provenienti da letture ogni 30 minuti e allo scoccare dell'ora e della mezz'ora (come per la stazione C), basta applicare dei filtri imponendo delle condizioni lungo le colonne *\"Datetime*\" e *\"Interval\"*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d06242",
   "metadata": {},
   "outputs": [],
   "source": [
    "stazioni = [\"A\",\"B\",\"C\"]\n",
    "\n",
    "for stazione in stazioni:\n",
    "    \n",
    "    print(f\"Stazione {stazione}\")\n",
    "    \n",
    "    df = globals()[\"df_\"+stazione].copy() #sono dati raw con colonna datetime unica e ordinata per datetime con nuovi indici\n",
    "    \n",
    "    # Il simbolo \"|\" sta ad indicare la funzione logica \"or\", mentre il simbolo \"&\" sta a indicare la funzione logica \"and\"\n",
    "    globals()[\"df_\"+stazione+\"_interval30\"] = df[((df.Datetime.dt.minute == 0)|(df.Datetime.dt.minute == 30))&(df.Interval == 30)]\n",
    "    print(globals()[\"df_\"+stazione+\"_interval30\"].Interval.min()) #verify\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5806b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ESEMPIO 2. Come sono distribuiti i dati rispetto gli anni e le stagioni?\n",
    "\n",
    "# Dividiamo i dati in stagioni\n",
    "stazioni = [\"A\",\"B\",\"C\"]\n",
    "\n",
    "for stazione in stazioni:\n",
    "    \n",
    "    print(f\"Stazione {stazione}\")\n",
    "    \n",
    "    df = globals()[\"df_\"+stazione+\"_interval30\"].copy()\n",
    "    \n",
    "    # Procediamo in questo modo:\n",
    "    \n",
    "    # 1. Applichiamo dei filtri per selezionare solo i mesi di interesse per le stagioni \"DJF\", \"MAM\", \"JJA\" e \"SON\"\n",
    "    \n",
    "    df_DJF = df[(df[\"Datetime\"].dt.month == 12)|(df[\"Datetime\"].dt.month == 1)|(df[\"Datetime\"].dt.month == 2)]\n",
    "    df_MAM = df[(df[\"Datetime\"].dt.month == 3)|(df[\"Datetime\"].dt.month == 4)|(df[\"Datetime\"].dt.month == 5)]\n",
    "    df_JJA = df[(df[\"Datetime\"].dt.month == 6)|(df[\"Datetime\"].dt.month == 7)|(df[\"Datetime\"].dt.month == 8)]\n",
    "    df_SON = df[(df[\"Datetime\"].dt.month == 9)|(df[\"Datetime\"].dt.month == 10)|(df[\"Datetime\"].dt.month == 11)]\n",
    "    \n",
    "    # 2. Raggruppiamo i dati in base agli anni del dataframe (con la funzione \"groupby()\")\n",
    "    # 3. Contiamo il numero di righe di ciascun anno (con la funzione aggregazione \"agg()\"), denominando la nuova colonna \n",
    "    # \"count_DJF\", etc.\n",
    "    # 4. Ripristiniamo l'indice degli anni come prima colonna del dataframe (con la funzione \"reset_index()\")\n",
    "    \n",
    "    count_DJF = df_DJF.groupby(df_DJF.Datetime.dt.year).agg(count_DJF=('Interval', 'size')).reset_index()\n",
    "    count_MAM = df_MAM.groupby(df_MAM.Datetime.dt.year).agg(count_MAM=('Interval', 'size')).reset_index()\n",
    "    count_JJA = df_JJA.groupby(df_JJA.Datetime.dt.year).agg(count_JJA=('Interval', 'size')).reset_index()\n",
    "    count_SON = df_SON.groupby(df_SON.Datetime.dt.year).agg(count_SON=('Interval', 'size')).reset_index()\n",
    "    \n",
    "    # 5. Concateniamo i 4 dataframes relativi alle stagioni in una lista\n",
    "    \n",
    "    dfs = [count_DJF, count_MAM, count_JJA, count_SON]\n",
    "    \n",
    "    # 6. Uniamo i dataframes (attraverso la funzione \"pd.merge()\") lungo la dimesione \"Datetime\" (specificando [on=\"Datetime\"]). \n",
    "    # La specifica [how=\"outer\"] serve a creare una prima colonna unendo gli anni di tutti i dataframes.\n",
    "    \n",
    "    df_merged = dfs[0].merge(dfs[1], on='Datetime', how='outer')\n",
    "    for df in dfs[2:]:\n",
    "        df_merged = df_merged.merge(df, on='Datetime', how='outer')\n",
    "    \n",
    "    # 7. Sostituico con zero i valori NaN.\n",
    "    # Dato che non tutti i dataframes hanno misurazioni in tutti gli anni, le misure mancanti vengono sostituite con \"NaN\" \n",
    "    # dalla funzione \"pd.merge()\"\n",
    "    \n",
    "    df_merged = df_merged.fillna(0).rename(columns={\"count_DJF\":\"DJF\",\"count_MAM\":\"MAM\",\"count_JJA\":\"JJA\",\"count_SON\":\"SON\"})\n",
    "    \n",
    "    globals()[\"count_\"+stazione] = df_merged\n",
    "    \n",
    "count_A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1967dc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "\n",
    "plt.figure(figsize=(8, 10))\n",
    "colors = {'SON': 'red', 'JJA': 'orange', 'MAM': 'green', 'DJF': 'blue'}\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "bottom = 0\n",
    "for stagione, color in colors.items():\n",
    "    plt.bar(count_A.Datetime, count_A[stagione], color=color, label=stagione,bottom=bottom)\n",
    "    bottom += count_A[stagione]\n",
    "plt.xlabel('Tempo (Anni)')\n",
    "plt.ylabel('Numero di misure')\n",
    "plt.title('Stazione A',fontweight=\"bold\")\n",
    "plt.legend()\n",
    "plt.xlim(2004,2020)\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "bottom = 0\n",
    "for stagione, color in colors.items():\n",
    "    plt.bar(count_B.Datetime, count_B[stagione], color=color, label=stagione,bottom=bottom)\n",
    "    bottom += count_B[stagione]\n",
    "plt.xlabel('Tempo (Anni)')\n",
    "plt.ylabel('Numero di misure')\n",
    "plt.title('Stazione B',fontweight=\"bold\")\n",
    "#plt.legend(reverse=True)\n",
    "plt.xlim(2004,2020)\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "bottom = 0\n",
    "for stagione, color in colors.items():\n",
    "    plt.bar(count_C.Datetime, count_C[stagione], color=color, label=stagione,bottom=bottom)\n",
    "    bottom += count_C[stagione]\n",
    "plt.xlabel('Tempo (Anni)')\n",
    "plt.ylabel('Numero di misure')\n",
    "plt.title('Stazione C',fontweight=\"bold\")\n",
    "#plt.legend(reverse=True)\n",
    "plt.xlim(2004,2020)\n",
    "\n",
    "plt.suptitle('Numero di misure per stagione e anno',fontweight=\"bold\",x=0.52)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d17ceb",
   "metadata": {},
   "source": [
    "Si noti un funzionamento discontinuo negli anni dal 2011 al 2013, mentre dal 2008 al 2010 e soprattutto dal 2014 al 2016 i dati sono abbastanza uniformemente distribuiti tra le annate e le stagioni, per poi peggiorare leggermente negli anni più recenti."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa385abe",
   "metadata": {},
   "source": [
    "  <span style=\"font-size: large;\">**2. Diagrammi a dispersione**  \n",
    "  \n",
    "  I diagrammi a dispersione, anche detti scatter plots, sono dei grafici costruiti andando a collezionare una serie di punti su uno spazio cartesiano, con ogni asse dello spazio rappresentato da una variabile di interesse. Questo tipo di grafico è particolarmente utile perché permette di evidenziare la relazione tra due o più variabili, individuando eventuali pattern e/o tendenze nei dati.  \n",
    "  \n",
    "  Si riporta di seguito, giusto a titolo esemplificativo, il diagramma a dispersione tra la variabile *\"Radiazione Totale\"* e *\"UV\"*, mappato in funzione della *\"Temperatura\"*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eeebea0",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "scatter_plot = plt.scatter(df_A_interval30['totRad'], df_A_interval30['UV'])\n",
    "\n",
    "plt.xlabel('Radiazione Totale (W m$^{-2}$)')\n",
    "plt.xlim(0,1050)\n",
    "\n",
    "plt.ylabel('UV')\n",
    "plt.ylim(0,10)\n",
    "\n",
    "plt.title('Scatter Plot di Radiazione Totale e UV, con Temperatura', fontweight=\"bold\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f6cb4b",
   "metadata": {},
   "source": [
    "I diagrammi a dispersione possono aggiungere più informazioni, andando a mappare la relazione tra le due variabili di interesse in funzione di una terza variabile. Si riporta di seguito, sempre a titolo di esempio, il diagramma a dispersione tra la variabile \"Radiazione Totale\" e \"UV\", mappato in funzione della \"Temperatura\", per la sola Stazione A."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539ca3f1",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "scatter_plot = plt.scatter(df_A_interval30['totRad'], df_A_interval30['UV'], \n",
    "                           c=df_A_interval30['outTemp'],vmin=0, vmax=30, cmap='YlOrRd')\n",
    "\n",
    "plt.xlabel('Radiazione Totale (W m$^{-2}$)')\n",
    "plt.xlim(0,1050)\n",
    "\n",
    "plt.ylabel('UV')\n",
    "plt.ylim(0,10)\n",
    "\n",
    "plt.colorbar(scatter_plot, label='Temperatura (°C)')\n",
    "\n",
    "plt.title('Scatter Plot di Radiazione Totale e UV, con Temperatura', fontweight=\"bold\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e559176c",
   "metadata": {},
   "source": [
    "  <span style=\"font-size: large;\">**3. Boxplots**  \n",
    "  \n",
    "  I boxplots sono uno strumento grafico utilizzato per visualizzare la distribuzione di un insieme di dati e per identificare le principali caratteristiche statistiche del dataset, quali ad es. media, mediana, primo quartile, terzo quartile, outliers e intervallo di confidenza al 95%.\n",
    "  \n",
    "  Si riporta di seguito, giusto a titolo esemplificativo, il boxplot della velocità del vento in funzione della stagione per la sola Stazione A. In questo caso, ciascun boxplot riporta la mediana della distribuzione (linea nera marcata), il primo (Q1) e terzo (Q3) quartile (estensione del boxplot), i valori *Q1-1.5IQR* e *Q3+1.5IQR* (*IQR* sta per *\"Inter-quartile range\"* ed è calcolato come *Q3-Q1*) (barre nere sottili) e outliers (tutti quei valori al di fuori del range di cui sopra, rappresentati come pallini)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc43327",
   "metadata": {},
   "source": [
    "# Prima di fare il boxplots, definiamo una funzione attraverso la quale riconosciamo la stagione di riferimento e la salviamo\n",
    "# nella nuova colonna \"Stagione\".\n",
    "\n",
    "# Inoltre, sono stati applicati dei filtri sulla velocità e direzione del vento, al fine di tenere solo i valori con un senso\n",
    "# fisico.\n",
    "\n",
    "def get_season(month):\n",
    "    if 3 <= month <= 5:\n",
    "        return 'MAM'\n",
    "    elif 6 <= month <= 8:\n",
    "        return 'JJA'\n",
    "    elif 9 <= month <= 11:\n",
    "        return 'SON'\n",
    "    else:\n",
    "        return 'DJF'\n",
    "\n",
    "df_A_interval30['Stagione'] = df_A_interval30['Datetime'].dt.month.apply(get_season)\n",
    "\n",
    "df = df_A_interval30\n",
    "df = df[(df['wndSpeed'] >= 0)&(df['wndSpeed']<=25)&(df['wndDir'] >= 0)&(df['wndDir']<360)]\n",
    "\n",
    "stagioni = ['DJF','MAM','JJA','SON']\n",
    "colori = ['blue','green','orange','red']\n",
    "            \n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "for i in range(len(stagioni)):\n",
    "    rgb = mcolors.to_rgba(colori[i])\n",
    "    linewidth = 1.5\n",
    "    edgecolor = 'black'\n",
    "    widths=0.6\n",
    "    data = df['wndSpeed'][df['Stagione']==stagioni[i]]\n",
    "    plt.boxplot(data, patch_artist=True, positions=np.array([i]),widths=widths,\n",
    "                  boxprops=dict(facecolor=(rgb[0], rgb[1], rgb[2], 0.3), edgecolor=edgecolor, linewidth=linewidth),\n",
    "                  medianprops=dict(color=edgecolor, linewidth=linewidth),\n",
    "                  whiskerprops=dict(color=edgecolor, linewidth=linewidth),\n",
    "                  capprops=dict(color=edgecolor, linewidth=linewidth),\n",
    "                  flierprops=dict(markeredgecolor=edgecolor))\n",
    "    \n",
    "plt.xticks(np.arange(0,len(stagioni)),stagioni)\n",
    "plt.ylabel(\"Velocità del vento (m s$^{-1}$)\")\n",
    "plt.title('Boxplots della Velocità del Vento per Stagione', fontweight=\"bold\")\n",
    "plt.ylim(-0.5,8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8024a8c",
   "metadata": {},
   "source": [
    "  <span style=\"font-size: large;\">**4. Timeseries**  \n",
    "    \n",
    "Analizzare le evoluzioni temporali delle variabili fisiche su specifiche scale temporali può fornire molte informazioni in merito ai fenomeni analizzati.  \n",
    "\n",
    "Si plottano di seguito, a titolo di esempio, i cicli diurni medi della velocità del vento e della temperatura della stazione A per le 4 stagioni DJF, MAM, JJA e SON."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfd2236",
   "metadata": {},
   "source": [
    "df = df_A_interval30\n",
    "df = df[(df['wndSpeed'] >= 0)&(df['wndSpeed']<=25)&(df['wndDir'] >= 0)&(df['wndDir']<360)]\n",
    "df = df[df['outTemp'] > -73.28]\n",
    "\n",
    "stagioni = ['DJF','MAM','JJA','SON']\n",
    "colori = ['blue','green','orange','red']\n",
    "\n",
    "fig_timeseries = plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i, stagione in enumerate(stagioni):\n",
    "\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    intensity = df[df['Stagione']==stagione].groupby(df.Datetime.dt.hour)['wndSpeed'].mean()\n",
    "    temperature = df[df['Stagione']==stagione].groupby(df.Datetime.dt.hour)['outTemp'].mean()\n",
    "    plt.plot(np.arange(0,24),intensity,color='black')\n",
    "    plt.ylim(0,1.75)\n",
    "    plt.xlim(0,23)\n",
    "    plt.title(stagione,fontweight='bold')\n",
    "    if i+1 in [1,3]:\n",
    "        plt.ylabel(\"Velocità del vento (m s$^{-1}$)\")\n",
    "    if i+1 in [3,4]:\n",
    "        plt.xlabel(\"Ora del giorno\")\n",
    "    \n",
    "    ax2 = plt.gca().twinx()\n",
    "    ax2.spines['right'].set_color('red')\n",
    "    ax2.tick_params(axis='y', colors='red')\n",
    "    ax2.plot(np.arange(0,24),temperature,color='red')\n",
    "#    ax2.set_ylim(0,30)\n",
    "    if i+1 in [2,4]:\n",
    "        ax2.set_ylabel('Temperatura (°C)',rotation=-90,labelpad=12,color='red')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63218d48-574b-4db8-9a03-4d6973c5db6b",
   "metadata": {},
   "source": [
    "<span style=\"font-size: x-large;\">**SALVATAGGIO**<span style=\"font-size: x-large;\">\n",
    "\n",
    "Una volta sviluppati i grafici di interesse, possiamo salvarli così da poterli adoperare per la redazione dell'elaborato finale.\n",
    "\n",
    "Si mostra a titolo di esempio come salvare il grafico delle timeseries appena sviluppato."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6390e391-cccb-4acb-9a6c-b44e5a857d6d",
   "metadata": {},
   "source": [
    "percorso = \"./FIGURE/\"\n",
    "name = 'StazioneA_Vento_vs_Temperatura.png'\n",
    "fig_timeseries.savefig(percorso+name) # \"fig_timeseries\" è il nome dato al grafico nella parte di codice della casella sopra. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4b77b4",
   "metadata": {},
   "source": [
    "<span style=\"font-size: x-large;\">**ANALISI DI DATI DI VENTO**<span style=\"font-size: x-large;\">  \n",
    "    \n",
    "Fatta questa piccola introduzione, iniziamo l'esperienza di laboratorio vera e propria, andando ad analizzare i dati di vento delle stazioni Davis.\n",
    "\n",
    "<span style=\"font-size: large;\">**FILTRI** \n",
    "    \n",
    "<span style=\"font-size: large;\">**1. Filtro temporale**  \n",
    "    \n",
    "Dall'istogramma espolaritivo della distribuzione dei dati mostrato in precedenza, si vede che le misure effettuate con le stazioni Davis non sono distribuite uniformemente nel tempo. Per questo motivo bisogna scegliere oculatamente l'intervallo temporale in cui svolgere le analisi, in modo da avere un numero alto di dati e distribuiti nel modo più omogeneo possibile sia tra le stagioni che tra le annate. \n",
    "    \n",
    "A titolo esemplificativo, si procede col filtrare le misure della stazione A. Nello specifico, si selezionano i dati del 2014, 2015 e 2016, che rispettano le condizioni di numerosità e omogeneità richiamate sopra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d86e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_season(month):\n",
    "    if 3 <= month <= 5:\n",
    "        return 'MAM'\n",
    "    elif 6 <= month <= 8:\n",
    "        return 'JJA'\n",
    "    elif 9 <= month <= 11:\n",
    "        return 'SON'\n",
    "    else:\n",
    "        return 'DJF'\n",
    "\n",
    "stazioni = [\"A\",\"B\",\"C\"]\n",
    "\n",
    "for stazione in stazioni:\n",
    "    print(\"STAZIONE_\"+stazione)\n",
    "    df = globals()[\"df_\"+stazione].copy()  #sono dati raw con colonna datetime unica e ordinata per datetime con nuovi indici\n",
    "\n",
    "    df['Stagione'] = df['Datetime'].dt.month.apply(get_season) #aggiungo indice di stagione\n",
    "    df_year = df[(df[\"Datetime\"].dt.year >= 2015)&(df[\"Datetime\"].dt.year <= 2016)]\n",
    "    globals()[\"df_\"+stazione+\"_year\"] = df_year\n",
    "    print(\"raw   \" + str(df_year.shape[0]))\n",
    "\n",
    "    # Qui riapplico la condizione già adoperata in precedenza in merito all'intervallo tra le misure.\n",
    "    # solo misure a 00 e 30 minuti\n",
    "    globals()[\"df_\"+stazione+\"_year_interval30\"] = df_year[((df_year.Datetime.dt.minute == 0)|(df_year.Datetime.dt.minute == 30))&\n",
    "                                 (df_year.Interval == 30)]\n",
    "    print(\"rimaste  \" + str(globals()[\"df_\"+stazione+\"_year_interval30\"].shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65476dde",
   "metadata": {},
   "source": [
    "  <span style=\"font-size: large;\">**2. Filtro di intensità e direzione**  \n",
    "\n",
    "Come indicato dalle linee guida dell'Environmental Protection Agency (EPA, Agenzia statunitense per la protezione dell'ambiente), le misure di vento possono essere considerate attendibili se vengono rispettate le seguenti condizioni sulla intensità e direzione del vento:  \n",
    "  - l'intensità del vento deve essere compresa tra 0 e 25 m/s;\n",
    "  - la direzione del vento deve essere compresa nell'intervallo [0° - 360°[ (le parentesi quadre non sono casuali: 0° è compreso, il 360° è escluso)  \n",
    "  \n",
    "Si applicano quindi dei filtri simili a quelli mostrati sopra per riprodurre il boxplot della velocità del vento in funzione della stagione, al fine di rispettare le linee guida EPA.\n",
    "\n",
    "<b>Mettiamo il range davis?????</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a4e834",
   "metadata": {},
   "outputs": [],
   "source": [
    "for stazione in stazioni:\n",
    "    \n",
    "    print(\"Stazione \"+stazione)\n",
    "    df_year_interval30_raw = globals()[\"df_\"+stazione+\"_year_interval30\"].copy() #dati filtrati per anno e risoluzione temp\n",
    "    n_raw = globals()[\"df_\"+stazione+\"_year_interval30\"].shape[0] #numero di righe (e di dati) non filtrati\n",
    "    print(\"raw \" + str(n_raw))\n",
    "    \n",
    "    df_year_interval30_wind = df_year_interval30_raw[\n",
    "        (df_year_interval30_raw['wndSpeed'] >= 0.5) & #range davis\n",
    "        (df_year_interval30_raw['wndSpeed']<=25) & \n",
    "        (df_year_interval30_raw['wndDir'] >= 0) & \n",
    "        (df_year_interval30_raw['wndDir']<360)]\n",
    "    \n",
    "    n_ok = float( df_year_interval30_wind.shape[0])\n",
    "    print(\"Vento buono \" + str(n_ok / n_raw * 100))\n",
    "    print(\"numero di dati \" + str(df_year_interval30_wind.shape[0]))\n",
    "\n",
    "    globals()[\"df_\"+stazione+\"_year_interval30_plaus\"] = df_year_interval30_wind\n",
    "\n",
    "    #separare filtro direzione e numero per statistica\n",
    "    globals()[\"df_\"+stazione+\"_year_interval30_plaus_speed\"] = df_year_interval30_wind = df_year_interval30_raw[\n",
    "        (df_year_interval30_raw['wndSpeed'] >= 0.5) & #range davis\n",
    "        (df_year_interval30_raw['wndSpeed']<=25)]\n",
    "    globals()[\"df_\"+stazione+\"_year_interval30_plaus_dir\"] = df_year_interval30_wind = df_year_interval30_raw[ \n",
    "        (df_year_interval30_raw['wndDir'] >= 0) & \n",
    "        (df_year_interval30_raw['wndDir']<360)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103c973e",
   "metadata": {},
   "source": [
    "  <span style=\"font-size: large;\">**3. Filtro sulla persistenza**  \n",
    "  \n",
    "Inoltre, sempre da linee guida EPA, le misure di vento sono da ritenere sospette se il vento (non nullo) non cambia di intensità per più di 0.1 m/s in 3 ore consecutive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RISOLUZIONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4efe95",
   "metadata": {},
   "outputs": [],
   "source": [
    "for stazione in stazioni:\n",
    "    print(\"stazione \"+stazione)\n",
    "    wndSpeed = globals()[\"df_\"+stazione+\"_year_interval30_plaus\"][\"wndSpeed\"].copy() #filtro anni, risoluzione temp, plausibilita\n",
    "    wndSpeed = wndSpeed.drop_duplicates()\n",
    "    wndSpeed = wndSpeed.sort_values()\n",
    "    #print(wndSpeed)\n",
    "    differences_speed = np.diff(wndSpeed)  # Compute consecutive differences\n",
    "    resolution_speed = np.min(differences_speed) if len(differences_speed) > 0 else None\n",
    "    print(f\"Wind Speed Resolution: {resolution_speed} units\")\n",
    "\n",
    "    wndDir = df = globals()[\"df_\"+stazione+\"_year_interval30_plaus\"][\"wndDir\"].copy() #filtro anni, risoluzione temp, plausibilita\n",
    "    wndDir = wndDir.drop_duplicates()\n",
    "    wndDir = wndDir.sort_values()\n",
    "    #print(wndDir)\n",
    "    differences_dir = np.diff(wndDir)  # Compute consecutive differences\n",
    "    resolution_dir = np.min(differences_dir) if len(differences_dir) > 0 else None\n",
    "    print(f\"Wind Direction Resolution: {resolution_dir} units\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variazione di almeno 0.1 m/s in 3 ore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metodo dev std leva a crescere da 0.1 a 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for stazione in stazioni:\n",
    "    print(\"stazione \"+stazione)\n",
    "    df = globals()[\"df_\"+stazione+\"_year_interval30_plaus\"].copy()\n",
    "\n",
    "    diff3h_backward = (df['Datetime'] - df['Datetime'].shift(5)).dt.total_seconds() / 3600.0\n",
    "    diff3h_forward = (df['Datetime'] - df['Datetime'].shift(-5)).dt.total_seconds() / 3600.0\n",
    "\n",
    "    std_backward = df['wndSpeed'].rolling(window=6).std()\n",
    "    std_foreward = df['wndSpeed'][::-1].rolling(window=6).std()[::-1]\n",
    "\n",
    "    df.insert(3,'diff3h_backward',diff3h_backward)\n",
    "    df.insert(4,'diff3h_forward',diff3h_forward)\n",
    "    df.insert(5,'std_backward',std_backward)\n",
    "    df.insert(6,'std_foreward',std_foreward)\n",
    "\n",
    "    #print(df.iloc[0:10, [0,3,4,5,6]])\n",
    "\n",
    "\n",
    "    df_excluded = df[\n",
    "        (df['wndSpeed'] > 0)&\n",
    "        ((df['diff3h_backward'] == 2.5)|(df['diff3h_forward'] == -2.5))&\n",
    "        ((df['std_backward'] <0.4 )|(df['std_foreward'] <0.4))\n",
    "    ]\n",
    "\n",
    "    df_year_interval30_wind_pers = df_year_interval30_wind[\n",
    "        ~df_year_interval30_wind['Datetime'].isin(df_excluded['Datetime'])]\n",
    "\n",
    "    globals()[\"df_\"+stazione+\"_year_interval30_plaus_pers1\"] = df_year_interval30_wind_pers\n",
    "    print(\"Eliminate \"+ str(df_excluded.shape[0]) + \" righe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f8a6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for stazione in stazioni:\n",
    "    print(\"stazione \"+stazione)\n",
    "    df = globals()[\"df_\"+stazione+\"_year_interval30_plaus\"].copy()\n",
    "\n",
    "    diff3h_backward = (df['Datetime'] - df['Datetime'].shift(5)).dt.total_seconds() / 3600.0\n",
    "    diff3h_forward = (df['Datetime'] - df['Datetime'].shift(-5)).dt.total_seconds() / 3600.0\n",
    "    #print(diff3h_backward.min())\n",
    "    print(df.shape[0])\n",
    "\n",
    "    diff_backward = df['wndSpeed'].rolling(window=6).max() - df['wndSpeed'].rolling(window=6).min()\n",
    "    diff_foreward = df['wndSpeed'][::-1].rolling(window=6).max()[::-1] - df['wndSpeed'][::-1].rolling(window=6).min()[::-1]\n",
    "\n",
    "    df.insert(3,'diff3h_backward',diff3h_backward)\n",
    "    df.insert(4,'diff3h_forward',diff3h_forward)\n",
    "    df.insert(5,'diff_backward',diff_backward)\n",
    "    df.insert(6,'diff_foreward',diff_foreward)\n",
    "\n",
    "    #print(df.iloc[0:10, [0,5,6,12]])\n",
    "    #print(df[(df['diff3h_backward'] < 22.5)][[\"Datetime\",\"wndDir\", 'diff3h_backward']])\n",
    "    \n",
    "    df_excluded = df[\n",
    "        ((df['diff3h_backward'] == 2.5)|(df['diff3h_forward'] == -2.5))&\n",
    "        ((df['diff_backward'] < 0.446 )|(df['diff_foreward'] < 0.446))\n",
    "    ]\n",
    "    print(\"Eliminate \"+ str(df_excluded.shape[0]) + \" righe\")\n",
    "\n",
    "    df_year_interval30_wind_pers = df[~df['Datetime'].isin(df_excluded['Datetime'])]\n",
    "\n",
    "    globals()[\"df_\"+stazione+\"_year_interval30_plaus_pers1\"] = df_year_interval30_wind_pers\n",
    "    print(\"Rimanenti \" + str(df_year_interval30_wind_pers.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "almeno 0.5 in 12 ore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c92ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for stazione in stazioni:\n",
    "    print(\"stazione \"+stazione)\n",
    "    df = globals()[\"df_\"+stazione+\"_year_interval30_plaus_pers1\"].drop(['diff3h_backward','diff3h_forward','diff_backward','diff_foreward'],axis=1).copy()\n",
    "\n",
    "    diff3h_backward = (df['Datetime'] - df['Datetime'].shift(23)).dt.total_seconds() / 3600.0\n",
    "    diff3h_forward = (df['Datetime'] - df['Datetime'].shift(-23)).dt.total_seconds() / 3600.0\n",
    "    #print(diff3h_backward.min())\n",
    "    print(df.shape[0])\n",
    "\n",
    "    diff_backward = df['wndSpeed'].rolling(window=24).max() - df['wndSpeed'].rolling(window=24).min()\n",
    "    diff_foreward = df['wndSpeed'][::-1].rolling(window=24).max()[::-1] - df['wndSpeed'][::-1].rolling(window=24).min()[::-1]\n",
    "\n",
    "    df.insert(3,'diff3h_backward',diff3h_backward)\n",
    "    df.insert(4,'diff3h_forward',diff3h_forward)\n",
    "    df.insert(5,'diff_backward',diff_backward)\n",
    "    df.insert(6,'diff_foreward',diff_foreward)\n",
    "\n",
    "    #print(df.iloc[0:10, [0,5,6,12]])\n",
    "    #print(df[(df['diff3h_backward'] < 22.5)][[\"Datetime\",\"wndDir\", 'diff3h_backward']])\n",
    "    \n",
    "    df_excluded = df[\n",
    "        ((df['diff3h_backward'] == 11.5)|(df['diff3h_forward'] == -11.5))&\n",
    "        ((df['diff_backward'] < 0.5 )|(df['diff_foreward'] < 0.5))\n",
    "    ]\n",
    "    print(\"Eliminate \"+ str(df_excluded.shape[0]) + \" righe\")\n",
    "\n",
    "    df_year_interval30_wind_pers = df[~df['Datetime'].isin(df_excluded['Datetime'])]\n",
    "\n",
    "    globals()[\"df_\"+stazione+\"_year_interval30_plaus_pers2\"] = df_year_interval30_wind_pers\n",
    "    print(\"Rimanenti \" + str(df_year_interval30_wind_pers.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "22.5 gradi per 3 pre --->> ???? in automatico ho tolto 22.5 gradi per 18 ore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stazione in stazioni:\n",
    "    print(\"stazione \"+stazione)\n",
    "    df = globals()[\"df_\"+stazione+\"_year_interval30_plaus_pers2\"].drop(['diff3h_backward','diff3h_forward','diff_backward','diff_foreward'],axis=1).copy()\n",
    "\n",
    "    diff3h_backward = (df['Datetime'] - df['Datetime'].shift(5)).dt.total_seconds() / 3600.0\n",
    "    diff3h_forward = (df['Datetime'] - df['Datetime'].shift(-5)).dt.total_seconds() / 3600.0\n",
    "    #print(diff3h_backward.min())\n",
    "    print(df.shape[0])\n",
    "\n",
    "    diff_backward = df['wndDir'].rolling(window=6).max() - df['wndDir'].rolling(window=6).min()\n",
    "    diff_foreward = df['wndDir'][::-1].rolling(window=6).max()[::-1] - df['wndDir'][::-1].rolling(window=6).min()[::-1]\n",
    "\n",
    "    df.insert(3,'diff3h_backward',diff3h_backward)\n",
    "    df.insert(4,'diff3h_forward',diff3h_forward)\n",
    "    df.insert(5,'diff_backward',diff_backward)\n",
    "    df.insert(6,'diff_foreward',diff_foreward)\n",
    "\n",
    "    #print(df.iloc[0:10, [0,5,6,12]])\n",
    "    #print(df[(df['diff3h_backward'] < 22.5)][[\"Datetime\",\"wndDir\", 'diff3h_backward']])\n",
    "    \n",
    "    df_excluded = df[\n",
    "        ((df['diff3h_backward'] == 2.5)|(df['diff3h_forward'] == -2.5))&\n",
    "        ((df['diff_backward'] < 22.5 )|(df['diff_foreward'] < 22.5))\n",
    "    ]\n",
    "    print(\"Eliminate \"+ str(df_excluded.shape[0]) + \" righe\")\n",
    "\n",
    "    df_year_interval30_wind_pers = df[\n",
    "        ~df['Datetime'].isin(df_excluded['Datetime'])]\n",
    "\n",
    "    globals()[\"df_\"+stazione+\"_year_interval30_plaus_pers3\"] = df_year_interval30_wind_pers\n",
    "    print(\"Rimanenti \" + str(df_year_interval30_wind_pers.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metodo dev std ne leva il doppio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for stazione in stazioni:\n",
    "    print(\"stazione \"+stazione)\n",
    "    df = globals()[\"df_\"+stazione+\"_year_interval30_plaus_pers2\"].copy()\n",
    "\n",
    "    diff3h_backward = (df['Datetime'] - df['Datetime'].shift(5)).dt.total_seconds() / 3600.0\n",
    "    diff3h_forward = (df['Datetime'] - df['Datetime'].shift(-5)).dt.total_seconds() / 3600.0\n",
    "\n",
    "    std_backward = df['wndDir'].rolling(window=6).std()\n",
    "    std_foreward = df['wndDir'][::-1].rolling(window=6).std()[::-1]\n",
    "\n",
    "    df.insert(3,'diff3h_backward',diff3h_backward)\n",
    "    df.insert(4,'diff3h_forward',diff3h_forward)\n",
    "    df.insert(5,'std_backward',std_backward)\n",
    "    df.insert(6,'std_foreward',std_foreward)\n",
    "\n",
    "    #print(df.iloc[0:10, [0,3,4,5,6]])\n",
    "\n",
    "\n",
    "    df_excluded = df[\n",
    "        ((df['diff3h_backward'] == 2.5)|(df['diff3h_forward'] == -2.5))&\n",
    "        ((df['std_backward'] <22.5 )|(df['std_foreward'] <22.5))\n",
    "    ]\n",
    "\n",
    "    df_year_interval30_wind_pers = df_year_interval30_wind[\n",
    "        ~df_year_interval30_wind['Datetime'].isin(df_excluded['Datetime'])]\n",
    "\n",
    "    globals()[\"df_\"+stazione+\"_year_interval30_plaus_pers3\"] = df_year_interval30_wind_pers\n",
    "    print(\"Eliminate \"+ str(df_excluded.shape[0]) + \" righe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TOTALE DATI TRATTENUTI dopo filtro anni, filtro risoluzione tempo, filtro plausib, filtro persist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stazione in stazioni:\n",
    "    n_raw = globals()[\"df_\"+stazione+\"_year_interval30\"].shape[0]  #sono dati raw, anni selezionati, con colonna datetime unica e ordinata per datetime con nuovi indici\n",
    "    n_fil = globals()[\"df_\"+stazione+\"_year_interval30_plaus_pers3\"].shape[0]\n",
    "\n",
    "    print(\"stazione_\"+stazione+\" trattenuti il \"+str(round(float(n_fil)/n_raw * 100, 2)) + \" % (\" + str(n_fil)+ \" dati)\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c4ca38",
   "metadata": {},
   "source": [
    "Si lascia allo studente di implementare autonomamente le condizioni di attendibilità suggerite dall'EPA che tengano in considerazione anche la persistenza della direzione del vento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from windrose import WindroseAxes\n",
    "\n",
    "print(\"Stazione_A\")\n",
    "ax = WindroseAxes.from_ax()\n",
    "\n",
    "ws = globals()[\"df_A_year_interval30_plaus_pers3\"][\"wndSpeed\"]\n",
    "wd = globals()[\"df_A_year_interval30_plaus_pers3\"][\"wndDir\"]\n",
    "print(\"min speed \" + str(ws.min()))\n",
    "print(\"max speed \" + str(ws.max()))\n",
    "\n",
    "ax.bar(wd, ws, normed=True, opening=0.9, edgecolor=\"white\")\n",
    "ax.set_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Stazione_B\")\n",
    "ax = WindroseAxes.from_ax()\n",
    "\n",
    "ws = globals()[\"df_B_year_interval30_plaus_pers3\"][\"wndSpeed\"]\n",
    "wd = globals()[\"df_B_year_interval30_plaus_pers3\"][\"wndDir\"]\n",
    "print(\"min speed \" + str(ws.min()))\n",
    "print(\"max speed \" + str(ws.max()))\n",
    "ax.bar(wd, ws, normed=True, opening=0.8, edgecolor=\"white\")\n",
    "ax.set_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Stazione_C\")\n",
    "ax = WindroseAxes.from_ax()\n",
    "\n",
    "ws = globals()[\"df_C_year_interval30_plaus_pers3\"][\"wndSpeed\"]\n",
    "wd = globals()[\"df_C_year_interval30_plaus_pers3\"][\"wndDir\"]\n",
    "print(\"min speed \" + str(ws.min()))\n",
    "print(\"max speed \" + str(ws.max()))\n",
    "ax.bar(wd, ws, normed=True, opening=0.8, edgecolor=\"white\")\n",
    "ax.set_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa0b8fa",
   "metadata": {},
   "source": [
    "<span style=\"font-size: large;\">**VISUALIZZAZIONE**  \n",
    "\n",
    "<span style=\"font-size: large;\">**1. Istogramma delle velocità del vento**  \n",
    "\n",
    "Andiamo a visualizzare l'istrogramma delle velocità filtrate, suddividendole per stagione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a8e017",
   "metadata": {},
   "outputs": [],
   "source": [
    "stagioni = ['DJF','MAM','JJA','SON']\n",
    "colori = ['blue','green','orange','red']\n",
    "\n",
    "for stazione in stazioni: \n",
    "    print(\"stazione_\"+stazione)\n",
    "    plt.figure(figsize=(8, 8))\n",
    "\n",
    "    df = globals()[\"df_\"+stazione+\"_year_interval30_plaus_pers3\"]\n",
    "    bins = np.arange(-0.25,6,0.5)\n",
    "\n",
    "    for i, stagione in enumerate(stagioni):\n",
    "\n",
    "        plt.subplot(2, 2, i+1)\n",
    "        data = df['wndSpeed'][df['Stagione']==stagione]\n",
    "        hist = sns.histplot(data, bins=bins,kde=False, color=colori[i])\n",
    "        plt.title(stagione,fontweight='bold')\n",
    "        plt.xlabel(\"Velocità del vento (m s$^{-1}$)\")\n",
    "        plt.ylabel(\"Numero di misure\")\n",
    "        plt.ylim(0,3500)\n",
    "        plt.xlim(-0.5,6.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229aa3d7",
   "metadata": {},
   "source": [
    "<span style=\"font-size: large;\">**2. Tabella riepilogativa**  \n",
    "\n",
    "Quanti dati abbiamo eliminato applicando i vari filtri?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa640c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stazioni = [\"A\",\"B\",\"C\"]\n",
    "def table_filter(stazione):\n",
    "    total = len(globals()[\"df_\"+stazione+\"_year\"])\n",
    "    interval = len(globals()[\"df_\"+stazione+\"_year_interval30\"])\n",
    "    intensity = len(globals()[\"df_\"+stazione+\"_year_interval30_plaus_speed\"])\n",
    "    direction = len(globals()[\"df_\"+stazione+\"_year_interval30_plaus_dir\"])\n",
    "    persistence = len(globals()[\"df_\"+stazione+\"_year_interval30_plaus_pers3\"])\n",
    "\n",
    "    dati = [['Total', 'Interval 30min', 'Intensity wind', 'Direction wind', 'Persistence'],\n",
    "            [total, interval, intensity, direction, persistence],\n",
    "        [str(round(total/total*100,2))+\"%\", \n",
    "            str(round(interval/total*100,2))+\"%\", \n",
    "                str(round(intensity/total*100,2))+\"%\", \n",
    "                    str(round(direction/total*100,2))+\"%\", \n",
    "                        str(round(persistence/total*100,2))+\"%\"]]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8,2))\n",
    "\n",
    "    ax.axis('off')\n",
    "\n",
    "    tabella = ax.table(cellText=dati, loc='center', cellLoc='center', colLabels=None)\n",
    "\n",
    "    for i in range(5):\n",
    "        tabella._cells[0, i].set_text_props(fontweight='bold')\n",
    "        \n",
    "    tabella.auto_set_font_size(False)\n",
    "    tabella.set_fontsize(10)\n",
    "    tabella.scale(1.5, 1.5)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "for stazione in stazioni:\n",
    "    table_filter(stazione)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe09f44a",
   "metadata": {},
   "source": [
    "Come possiamo vedere, il grosso dei dati filtrati viene escluso dal filtro sulla persistenza.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a52e08",
   "metadata": {},
   "source": [
    "<span style=\"font-size: large;\">**3. Dati disponibili per mese**  \n",
    "\n",
    "Analizziamo ora l’andamento mensile delle percentuali di istanti di funzionamento della strumentazione (dati validi) rispetto al totale degli istanti disponibili."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2e3e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raggruppa per mese e conta il numero di dati in ogni mese\n",
    "df_monthly_count = df_A_year.groupby(df_A_year['Datetime'].dt.month).size().reset_index(name='Count')\n",
    "df_monthly_count_filtered = df_A_year_interval30_inten_dir_pers.groupby(\n",
    "    df_A_year_interval30_inten_dir_pers['Datetime'].dt.month).size().reset_index(name='Count')\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.bar(df_monthly_count['Datetime'], df_monthly_count['Count'])\n",
    "plt.xticks(df_monthly_count['Datetime'], calendar.month_abbr[1:])\n",
    "plt.xlabel('Mese')\n",
    "plt.ylabel('Numero dati')\n",
    "plt.ylim(0,5000)\n",
    "plt.title(\"Numero dati nel dataframe originale\", fontweight='bold')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "percentage = df_monthly_count_filtered['Count']/df_monthly_count['Count']*100\n",
    "bars = plt.bar(df_monthly_count_filtered['Datetime'], percentage)\n",
    "plt.xticks(df_monthly_count_filtered['Datetime'], calendar.month_abbr[1:])\n",
    "plt.xlabel('Mese')\n",
    "plt.ylabel('Percentuale dati validi (%)')\n",
    "plt.ylim(80,100)\n",
    "plt.title(\"Percentuale dati validi\", fontweight='bold')\n",
    "\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.1, f'{round(yval, 2)}%', ha='center', \n",
    "             va='bottom', fontsize=\"small\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d62aaf",
   "metadata": {},
   "source": [
    "<span style=\"font-size: large;\">**CONFRONTO TRA STAZIONI DIVERSE**  \n",
    "\n",
    "Un altro step importante dell'esperienza di laboratiorio è confrontare i dati delle stazioni Davis e, inoltre, valutare la loro rappresentatività tramite il confronto con i dati ufficiali ARPAE.  \n",
    "\n",
    "Prima di procedere con l'analisi dei dati ARPAE, andiamo a vedere brevemente qualche possibile analisi da sviluppare per il confronto di due stazioni di misura.  \n",
    "\n",
    "A tal fine, si crea un dataset fittizio da paragonare con i dati della stazione A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da7339d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = df_A_year_interval30_inten_dir_pers.copy()\n",
    "\n",
    "df_new = df_A_year_interval30_inten_dir_pers.copy()\n",
    "# Aggiungiamo un rumore casuale alla velocità del vento\n",
    "df_new['wndSpeed'] = df_new['wndSpeed'] * (np.random.normal(loc=1, scale=0.2, size=len(df)) +\n",
    "                                           np.random.normal(loc=0, scale=0.3, size=len(df)))\n",
    "\n",
    "# Riporta alla risoluzione originale\n",
    "df_new['wndSpeed'] = 0.447 * (df_new['wndSpeed'] // 0.447)\n",
    "\n",
    "df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45167ac",
   "metadata": {},
   "source": [
    "Per confrontare i dati di due stazioni, si possono adoperare diversi indici statistici, quali ad esempio:\n",
    "- Indice di correlazione,\n",
    "- Mean Error (ME),\n",
    "- Mean Absolute Error (MAE),\n",
    "- Root Mean Square Error (RMSE),\n",
    "- RMSE normalizzato con la media del dataset di riferimento,\n",
    "\n",
    "Al fine di evitare di riscrivere le singole funzioni per ogni comparazione tra singole coppie di stazioni e rendere lo script eccessivamente lungo e ridondante, conviene definire una funzione con cui calcolare tutti gli indici desiderati e richiamarla ogni qualvolta se ne abbia bisogno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e8962d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistics(var,ref):\n",
    "    \n",
    "    # INPUT:\n",
    "    # - var: Dataframe with the variable of interest\n",
    "    # - ref: Reference dataframe with the variable of interest\n",
    "    # Per avere senso fisico, \"var\" e \"ref\" devono avere le stesse date\n",
    "    \n",
    "    # OUTPUT:\n",
    "    # - CORR: Correlation\n",
    "    # - ME: Mean Error\n",
    "    # - MAE: Mean Absolute Error\n",
    "    # - RMSE: Root Mean Square Error\n",
    "    # - nRMSE: Normalized RMSE\n",
    "    \n",
    "    CORR = var.corrwith(ref)[0]\n",
    "    ME = np.mean(np.subtract(var, ref))\n",
    "    MAE = np.mean(np.abs(np.subtract(var, ref)))\n",
    "    RMSE = np.sqrt(np.nanmean(np.square(np.subtract(var, ref))))\n",
    "    nRMSE = RMSE / np.nanmean(ref)\n",
    "    \n",
    "    return CORR, ME, MAE, RMSE, nRMSE\n",
    "\n",
    "corr,me,mae,rmse,nrmse = statistics(df_new[['wndSpeed']],df[['wndSpeed']])\n",
    "\n",
    "table = pd.DataFrame({\n",
    "    'Corr.': [round(corr,3)],\n",
    "    'ME': [round(me,3)],\n",
    "    'MAE': [round(mae,3)],\n",
    "    'RMSE': [round(rmse,3)],\n",
    "    'normalized RMSE': [round(nrmse,3)]\n",
    "})\n",
    "\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd754195",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new[['wndSpeed']].corrwith(df[['wndSpeed']]).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581888a2",
   "metadata": {},
   "source": [
    "Un altro modo per confrontare due datasets è adoperare specifiche rappresentazioni grafiche quali ad esempio istogrammi, diagrammi di dispersione, boxplots, etc. \n",
    "\n",
    "Plottiamo di seguito, a titolo di esempio, un grafico a dispersione tra i dati della stazione A e i dati della stazione fittizia, con l'aggiunta della regressione lineare dei dati della stazione fittizia sui dati della stazione A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6c05d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regressione Lineare\n",
    "model = LinearRegression()\n",
    "model.fit(df['wndSpeed'].to_numpy().reshape((-1, 1)),df_new['wndSpeed'].to_numpy())\n",
    "intercept = model.intercept_\n",
    "slope = model.coef_[0]\n",
    "\n",
    "# Definizione delle grandezze dei marker, in funzione della numerosità\n",
    "c = Counter(zip(df['wndSpeed'],df_new['wndSpeed']))\n",
    "s = [0.06*c[(xx,yy)] for xx,yy in zip(df['wndSpeed'],df_new['wndSpeed'])]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "\n",
    "# Linea diagonale, che rappresenta una relazione lineare tra le due stazioni\n",
    "ax.axline((1, 1), slope=1, color='lightgrey',linewidth=0.5)\n",
    "ax.axline((0, intercept), slope=slope, color='red',linewidth=0.5) \n",
    "\n",
    "scatter_plot = plt.scatter(df['wndSpeed'], df_new['wndSpeed'],s=s,color='blue',label='Numero di occorrenze')\n",
    "\n",
    "plt.xlabel('Stazione A (m s$^{-1}$)')\n",
    "plt.ylabel('Stazione Fittizia (m s$^{-1}$)')\n",
    "plt.xlim(-1,12)\n",
    "plt.ylim(-1,12)\n",
    "\n",
    "ax.legend(*scatter_plot.legend_elements(prop=\"sizes\", num=[1,10,30,50,100,200],color='blue'), loc=(0.84,0.01),title='Numerosità')\n",
    "\n",
    "plt.text(8,6.9,f'y = {round(intercept,2)} + {round(slope,2)}*x',rotation=np.rad2deg(math.atan(slope)),color='red')\n",
    "plt.title('Velocità del vento\\nStazione A vs Stazione Fittizia', fontweight=\"bold\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644fc691",
   "metadata": {},
   "source": [
    "<span style=\"font-size: large;\">**DATI ARPAE**  \n",
    "    \n",
    "I dati delle stazioni della rete regionale ARPAE sono scaricabili liberamente dalla piattaforma dext3r (https://simc.arpae.it/dext3r/) selezionando il periodo e le variabili prescelte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9052a2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "percorso = \"C:/Users/luca.famoosspaolini/Desktop/Laboratorio/DATI_ARPAE/\"\n",
    "\n",
    "year = ['2014','2015','2016']\n",
    "\n",
    "for y in year:\n",
    "\n",
    "    file = percorso+f'{y}.csv'\n",
    "    \n",
    "    # Eliminiamo le prime 6 righe che sono dati testuali e gli ultimi valori dell'anno precedente\n",
    "    df = pd.read_csv(file, encoding='ISO-8859-1',names=['Datetime','Fine validità (UTC)','wndSpeed'],\n",
    "                     skiprows=6,on_bad_lines='skip')\n",
    "    # Eliminiamo inoltre le ultime righe che hanno solo dati testuali\n",
    "    df = df[:-2]\n",
    "    # Eliminiamo la colonna \"Fine validità (UTC)\" in quanto disponiamo dell'informazione sulla data già dalla prima colonna.\n",
    "    # La seconda colonna ci sta solo ad indicare che le misure sono misure di vento orarie (come già noto dal sito web ARPAE).\n",
    "    df.drop(df.columns[1],axis=1, inplace=True)\n",
    "    \n",
    "    # Trasformiamo la colonna tempo in formato Data Anno-Mese-Giorno ora:minuto (come fatto in precedenza)\n",
    "    df['Datetime'] = pd.to_datetime(df['Datetime']).dt.strftime('%Y-%m-%d %H:%M:00')\n",
    "    \n",
    "    globals()['df_'+y] = df\n",
    "\n",
    "# Infine, concateniamo i tre dataframe lungo la dimensione temporale, per creare un unico dataframe ARPAE\n",
    "df_ARPAE = pd.concat([df_2014, df_2015, df_2016], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d5cfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ARPAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb093da",
   "metadata": {},
   "source": [
    "\"Datetime\" è fornito nella scalata temporale Coordinated Universal Time (UTC), mentre le stazioni Davis di UniBo sono in ora locale (timezone CET). Dobbiamo quindi convertire le stazioni Davis di UniBo nel formato UTC, al fine di rendere paragonabili le misure.  \n",
    "\n",
    "Per farlo, adoperiamo il pacchetto Python *\"pytz\"*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b2819d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A = df_A_year_interval30_inten_dir_pers.copy()\n",
    "\n",
    "# Prima dobbiamo definire la scala temporale del date delle stazioni, vale a dire \"Europe/Rome\".\n",
    "time = df_A.Datetime.dt.tz_localize(\"Europe/Rome\",ambiguous='NaT')\n",
    "\n",
    "# Poi, possiamo convertirle in 'UTC' e riscriverlo nel formato Anno-Mese-Giorno Ora:minuto:00\n",
    "df_A['Datetime'] = time.dt.tz_convert('UTC').dt.strftime('%Y-%m-%d %H:%M:00')\n",
    "\n",
    "# Come potete vedere, le date in 'Datetime' sono state anticipate.\n",
    "df_A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aed5c78",
   "metadata": {},
   "source": [
    "A questo punto, possiamo confrontare la stazione A con la stazione ARPAE, facendo attenzione a garantire la corrispondenza temporale dei due datasets.  \n",
    "\n",
    "A titolo di esempio, si riporta il grafico a dispersione dell'intensità del vento per le due stazioni."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135bffd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A = df_A[['Datetime','wndSpeed']]\n",
    "df_merged = pd.merge(df_A, df_ARPAE, on='Datetime', suffixes=('_A', '_ARPAE'))\n",
    "df_merged = df_merged.dropna()\n",
    "\n",
    "# Regressione Lineare\n",
    "model = LinearRegression()\n",
    "model.fit(df_merged['wndSpeed_ARPAE'].to_numpy().reshape((-1, 1)),df_merged['wndSpeed_A'].to_numpy())\n",
    "intercept = model.intercept_\n",
    "slope = model.coef_[0]\n",
    "\n",
    "# Definizione delle grandezze dei marker, in funzione della numerosità\n",
    "c = Counter(zip(df_merged['wndSpeed_ARPAE'],df_merged['wndSpeed_A']))\n",
    "s = [0.2*c[(xx,yy)] for xx,yy in zip(df_merged['wndSpeed_ARPAE'],df_merged['wndSpeed_A'])]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "\n",
    "# Linea diagonale, che rappresenta una relazione lineare tra le due stazioni\n",
    "ax.axline((1, 1), slope=1, color='lightgrey',linewidth=0.5)\n",
    "ax.axline((0, intercept), slope=slope, color='red',linewidth=0.5) \n",
    "\n",
    "scatter_plot = plt.scatter(df_merged['wndSpeed_ARPAE'],df_merged['wndSpeed_A'],s=s,color='blue',label='Numero di occorrenze')\n",
    "\n",
    "plt.xlabel('Stazione ARPAE (m s$^{-1}$)')\n",
    "plt.ylabel('Stazione A (m s$^{-1}$)')\n",
    "plt.xlim(-1,12)\n",
    "plt.ylim(-1,12)\n",
    "\n",
    "ax.legend(*scatter_plot.legend_elements(prop=\"sizes\", num=[1,10,20,30,60],color='blue'), loc=(0.84,0.01),title='Numerosità')\n",
    "\n",
    "plt.text(8,3.5,f'y = {round(intercept,2)} + {round(slope,2)}*x',rotation=np.rad2deg(math.atan(slope)),color='red')\n",
    "plt.title('Velocità del vento\\nStazione ARPAE vs Stazione A', fontweight=\"bold\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c597dd",
   "metadata": {},
   "source": [
    "Come ulteriore esempio, plottiamo gli istrogrammi delle due stazioni nel medesimo plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2166501",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged\n",
    "\n",
    "fig_hist = plt.figure(figsize=(8, 6))\n",
    "\n",
    "bins = np.arange(-0.25,6,0.5)\n",
    "\n",
    "hist = sns.histplot(data=df_merged[['wndSpeed_A','wndSpeed_ARPAE']].melt(), x='value', hue='variable', bins=bins, \n",
    "             multiple='dodge',palette={'wndSpeed_A': 'darkblue', 'wndSpeed_ARPAE': 'darkorange'})\n",
    "\n",
    "# ISTOGRAMMI delle singole stazioni\n",
    "#sns.histplot(df_merged['wndSpeed_A'], bins=bins,kde=False, color='blue')\n",
    "#sns.histplot(df_merged['wndSpeed_ARPAE'], bins=bins,kde=False, color='orange')\n",
    "\n",
    "plt.title('Istogramma velocità del vento',fontweight='bold')\n",
    "plt.xlabel(\"Velocità del vento (m s$^{-1}$)\")\n",
    "plt.ylabel(\"Numero di misure\")\n",
    "plt.ylim(0,6000)\n",
    "plt.xlim(-0.5,6.5)\n",
    "\n",
    "legend = hist.get_legend()\n",
    "handles = legend.legendHandles\n",
    "legend.remove()\n",
    "plt.legend(handles, ['Stazione A', 'Stazione ARPAE'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "20ce54e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. DATI per rosa dei venti\n",
    "\n",
    "# Selezioniamo solo i dati all'inizio dell'ora\n",
    "df = df_A_year_interval30_inten_dir_pers.copy()\n",
    "df = df[df['Datetime'].dt.minute == 0]\n",
    "df = df[['Datetime','wndSpeed','wndDir']]\n",
    "\n",
    "# Ristrutturiamo i dati nel formato richiesto da WRPlot\n",
    "\n",
    "df_WRPlot = pd.DataFrame({\n",
    "    'StID': [12345] * len(df),\n",
    "    'YYYY': df['Datetime'].dt.year.apply(pd.to_numeric),\n",
    "    'MM': df['Datetime'].dt.month.apply(pd.to_numeric),\n",
    "    'DD': df['Datetime'].dt.day.apply(pd.to_numeric),\n",
    "    'HH': df['Datetime'].dt.hour.apply(pd.to_numeric),\n",
    "    'Dir': df['wndDir'].apply(pd.to_numeric).astype(int),\n",
    "    'WS': (1.94384 * df['wndSpeed']).apply(pd.to_numeric).astype(int) # (1 knot = 1.94384 m/s)\n",
    "})\n",
    "\n",
    "percorso = \"C:/Users/luca.famoosspaolini/Desktop/Laboratorio/DATI_PROCESSATI/\"\n",
    "df_WRPlot.to_csv(percorso+'Venti_Stazione_A.txt', sep='\\t',index = False, header=False)\n",
    "\n",
    "file_path = percorso+'Venti_Stazione_A.txt'\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    contenuto = file.read()\n",
    "\n",
    "with open(file_path, 'w') as file:\n",
    "    file.write(\"LAKES FORMAT\" + \"\\n\" + contenuto)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
